"""
Planning strategies for AgentTool.

Strategies define HOW the agent decides what to do next:
- DirectStrategy: Single LLM call with tool_calling (simple, fast)
- ReactStrategy: Reason first, then act on immediate next step (thoughtful, adaptive)
- AdaptStrategy: Try simple first, decompose on failure (structural adaptation)
- ReflexionStrategy: Learn from mistakes through reflection (behavioral adaptation)
- AdaptiveReflexionStrategy: Combined ADaPT + Reflexion (multi-layered recovery)

The Strategy Pattern allows swapping planning approaches without changing AgentTool.

## LLM Response Handling

All strategies handle LLM responses according to these rules:

| LLM Response               | finished | success                           | tool_calls    |
|----------------------------|----------|-----------------------------------|---------------|
| No tool_calls returned     | True     | False (unsuccessful termination)  | []            |
| FINISH tool called         | True     | From FINISH args (default: True)  | []            |
| Other tool_calls returned  | False    | N/A                               | [tool_calls]  |

Key behaviors:
- **No tool_calls**: Treated as unsuccessful finish. The LLM failed to call any tool,
  including the FINISH tool, so we cannot determine intent. This prevents silent failures.
- **FINISH tool**: The `success` field is extracted from the FINISH tool's arguments,
  allowing explicit success/failure signaling (e.g., FINISH(result="Cannot proceed", success=false)).
- **Other tools**: Strategy returns tool_calls for AgentTool to execute; loop continues.
"""

from abc import ABC, abstractmethod
import typing as t

from openai.types.chat import ChatCompletionMessageParam
from pydantic import BaseModel, ConfigDict, Field

from agents.llm_core.llm_client import ToolCall
from agents.tools_core.base_tool import BaseTool


class StrategyOutput(BaseModel):
    """
    Output from a planning strategy.

    Represents one of three states:
    1. **Task finished successfully**: finished=True, success=True, result=<output>
    2. **Task finished unsuccessfully**: finished=True, success=False, result=<reason>
    3. **Task in progress**: finished=False, tool_calls=[...] (tools to execute)

    The `success` field is only meaningful when `finished=True`. It reflects:
    - The FINISH tool's `success` argument when FINISH is called explicitly
    - `False` when the LLM returns no tool_calls (unsuccessful termination)
    - `True` by default for successful completion

    AgentTool propagates `success` to `AgentToolOutput.success`.
    """

    model_config = ConfigDict(arbitrary_types_allowed=True)

    # Messages generated by the strategy (e.g., reasoning)
    # These get added to the conversation history
    messages: list[ChatCompletionMessageParam] = Field(default_factory=list)

    # Tool calls to execute (if any) - uses ToolCall from llm_client
    tool_calls: list[ToolCall] = Field(default_factory=list)

    # Whether the task is complete
    finished: bool = Field(default=False)

    # Whether the task completed successfully (only meaningful when finished=True)
    # Reflects the success parameter from the FINISH tool call
    success: bool = Field(default=True)

    # Final result (if finished)
    result: str | None = Field(default=None)


class PlanningStrategy(ABC):
    """
    Base class for planning strategies.

    A strategy receives the current conversation state and decides:
    1. What messages to add (e.g., reasoning)
    2. What tools to call (if any)
    3. Whether the task is finished

    Each strategy owns its LLM client(s) and model configuration.
    """

    @abstractmethod
    async def plan(
        self,
        messages: list[ChatCompletionMessageParam],
        tools: list[BaseTool[t.Any, t.Any]],
        parallel_tool_calls: bool = True,
    ) -> StrategyOutput:
        """
        Generate next actions based on current conversation state.

        Args:
            messages: Current conversation history
            tools: Available tools (including finish tool)
            parallel_tool_calls: Allow LLM to return multiple tool calls

        Returns:
            StrategyOutput with messages, tool_calls, and/or finished status
        """
        pass
